{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import UnstructuredReader\n",
    "from pathlib import Path\n",
    "\n",
    "subjects = ['Biology', 'Chemistry', 'Physics', 'Mathematics', 'Computer_science']\n",
    "\n",
    "loader = UnstructuredReader()\n",
    "doc_set = {}\n",
    "all_docs = []\n",
    "for subject in subjects:\n",
    "    subject_docs = loader.load_data(\n",
    "        file=Path(f\"./data/{subject}.pdf\"), split_documents=False\n",
    "    )\n",
    "    # insert year metadata into each year\n",
    "    for s in subject_docs:\n",
    "        s.metadata = {\"subject\": subject}\n",
    "    doc_set[subject] = subject_docs\n",
    "    all_docs.extend(subject_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Configure document chunking size\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "index_set = {}\n",
    "for subject in subjects:\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    cur_index = VectorStoreIndex.from_documents(\n",
    "        doc_set[subject],\n",
    "        storage_context=storage_context,\n",
    "        embed_model=embed_model,  # use the open source embeddings model\n",
    "    )\n",
    "    index_set[subject] = cur_index\n",
    "    storage_context.persist(persist_dir=f\"./storage/{subject}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
